{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69e386c4",
   "metadata": {},
   "source": [
    "# Spatial and Longitudinal Analysis in Active Transportation Research\n",
    "\n",
    "This notebook demonstrates how to use the spatial and longitudinal data handling capabilities of the CISD package for active transportation research.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Transportation infrastructure interventions often have:\n",
    "1. **Spatial spillover effects**: The impact can extend beyond the immediate intervention area\n",
    "2. **Temporal dynamics**: Effects can evolve over time after implementation\n",
    "\n",
    "This tutorial covers:\n",
    "1. Working with geospatial data in causal inference\n",
    "2. Handling longitudinal (panel) data in before-after studies\n",
    "3. Accounting for spatial dependencies in treatment effects\n",
    "4. Event study analysis of intervention timing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb8562a",
   "metadata": {},
   "source": [
    "## Setup and Dependencies\n",
    "\n",
    "First, let's import the necessary libraries and configure the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c641ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Import CISD modules\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Spatial dependencies\n",
    "try:\n",
    "    import geopandas as gpd\n",
    "    from shapely.geometry import Point\n",
    "    import contextily as ctx\n",
    "    HAS_SPATIAL = True\n",
    "except ImportError:\n",
    "    HAS_SPATIAL = False\n",
    "    print(\"Spatial dependencies require: pip install geopandas shapely contextily libpysal\")\n",
    "\n",
    "# Import CISD spatial-temporal utilities\n",
    "try:\n",
    "    from cisd.spatial_temporal import (SpatialDependencyHandler,\n",
    "                                     LongitudinalDataHandler, \n",
    "                                     create_spatial_panel_data)\n",
    "    from cisd.visualization import plot_spatial_effects\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing spatial dependencies: {e}\")\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set_context(\"talk\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c816b4b",
   "metadata": {},
   "source": [
    "## 1. Creating a Synthetic Spatial Dataset\n",
    "\n",
    "Let's create a synthetic dataset with spatial properties based on a real geographic area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590e8bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_spatial_data(n_points=100, bbox=None, random_state=42):\n",
    "    \"\"\"\n",
    "    Create a synthetic point dataset with spatial properties.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_points : int, default=100\n",
    "        Number of points to generate\n",
    "    bbox : tuple, optional\n",
    "        Bounding box (xmin, ymin, xmax, ymax)\n",
    "    random_state : int, default=42\n",
    "        Random seed\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    gdf : geopandas.GeoDataFrame\n",
    "        GeoDataFrame with synthetic points\n",
    "    \"\"\"\n",
    "    if not HAS_SPATIAL:\n",
    "        raise ImportError(\"This function requires geopandas and shapely.\")\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Default to Salt Lake City area if no bbox provided\n",
    "    if bbox is None:\n",
    "        bbox = (-112.1, 40.7, -111.8, 40.85)  # Salt Lake City approximate bbox\n",
    "    \n",
    "    # Generate random points within the bbox\n",
    "    x = np.random.uniform(bbox[0], bbox[2], n_points)\n",
    "    y = np.random.uniform(bbox[1], bbox[3], n_points)\n",
    "    \n",
    "    # Create geometry column\n",
    "    geometry = [Point(xy) for xy in zip(x, y)]\n",
    "    \n",
    "    # Create GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        {\n",
    "            'location_id': range(n_points),\n",
    "            'walkability': np.random.normal(5, 1.5, n_points),\n",
    "            'population': np.random.poisson(1000, n_points),\n",
    "            'income': np.random.lognormal(10, 0.5, n_points)\n",
    "        },\n",
    "        geometry=geometry,\n",
    "        crs=\"EPSG:4326\"  # WGS84 coordinate system\n",
    "    )\n",
    "    \n",
    "    # Create treatment variable (more likely near the center)\n",
    "    center_x = (bbox[0] + bbox[2]) / 2\n",
    "    center_y = (bbox[1] + bbox[3]) / 2\n",
    "    \n",
    "    # Calculate distance to center\n",
    "    gdf['dist_to_center'] = gdf.geometry.apply(\n",
    "        lambda p: ((p.x - center_x)**2 + (p.y - center_y)**2)**0.5\n",
    "    )\n",
    "    \n",
    "    # Treatment more likely close to center\n",
    "    p_treatment = 1 / (1 + np.exp(5 * gdf['dist_to_center'] / gdf['dist_to_center'].max()))\n",
    "    gdf['treatment'] = np.random.binomial(1, p_treatment)\n",
    "    \n",
    "    # Generate outcome with spatial correlation\n",
    "    # Base outcome depends on covariates\n",
    "    outcome_base = 0.5 * gdf['walkability'] + 0.3 * np.log(gdf['income'] / 10000)\n",
    "    \n",
    "    # Treatment effect\n",
    "    treatment_effect = 2.0 * gdf['treatment']\n",
    "    \n",
    "    # Add spatially correlated noise\n",
    "    # Simple approach: closer points have more similar noise\n",
    "    from sklearn.metrics.pairwise import euclidean_distances\n",
    "    coords = np.column_stack([gdf.geometry.x, gdf.geometry.y])\n",
    "    dist_matrix = euclidean_distances(coords)\n",
    "    \n",
    "    # Convert distances to similarities\n",
    "    sim_matrix = np.exp(-dist_matrix / dist_matrix.mean())\n",
    "    \n",
    "    # Generate correlated noise\n",
    "    noise_seed = np.random.normal(0, 1, n_points)\n",
    "    spatial_noise = sim_matrix @ noise_seed / sim_matrix.sum(axis=1)\n",
    "    \n",
    "    # Final outcome\n",
    "    gdf['outcome'] = outcome_base + treatment_effect + spatial_noise + np.random.normal(0, 0.5, n_points)\n",
    "    \n",
    "    return gdf\n",
    "\n",
    "# Create synthetic spatial data\n",
    "if HAS_SPATIAL:\n",
    "    spatial_df = create_synthetic_spatial_data(n_points=150)\n",
    "    print(f\"Created synthetic spatial dataset with {len(spatial_df)} points\")\n",
    "    spatial_df.head()\n",
    "else:\n",
    "    print(\"Skipping spatial data creation due to missing dependencies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bc2492",
   "metadata": {},
   "source": [
    "## 2. Visualizing the Spatial Data\n",
    "\n",
    "Let's plot our synthetic data to understand its spatial structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c415ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_SPATIAL:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # Plot 1: Treatment assignment\n",
    "    spatial_df.plot(\n",
    "        column='treatment', \n",
    "        ax=axes[0],\n",
    "        categorical=True,\n",
    "        legend=True,\n",
    "        markersize=50,\n",
    "        alpha=0.7,\n",
    "        cmap='viridis'\n",
    "    )\n",
    "    axes[0].set_title('Treatment Assignment')\n",
    "    \n",
    "    # Plot 2: Walkability\n",
    "    spatial_df.plot(\n",
    "        column='walkability',\n",
    "        ax=axes[1],\n",
    "        legend=True,\n",
    "        markersize=50,\n",
    "        alpha=0.7,\n",
    "        cmap='YlOrRd'\n",
    "    )\n",
    "    axes[1].set_title('Walkability Score')\n",
    "    \n",
    "    # Plot 3: Outcome\n",
    "    spatial_df.plot(\n",
    "        column='outcome',\n",
    "        ax=axes[2],\n",
    "        legend=True,\n",
    "        markersize=50,\n",
    "        alpha=0.7,\n",
    "        cmap='RdYlGn'\n",
    "    )\n",
    "    axes[2].set_title('Outcome Variable')\n",
    "    \n",
    "    # Add basemaps if contextily is available\n",
    "    try:\n",
    "        for ax in axes:\n",
    "            ctx.add_basemap(\n",
    "                ax, \n",
    "                crs=spatial_df.crs.to_string(),\n",
    "                source=ctx.providers.CartoDB.Positron\n",
    "            )\n",
    "            ax.set_axis_off()\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding basemap: {e}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "else:\n",
    "    print(\"Skipping visualization due to missing dependencies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaa49e6",
   "metadata": {},
   "source": [
    "## 3. Handling Spatial Dependencies in Causal Inference\n",
    "\n",
    "Now we'll use the `SpatialDependencyHandler` class to account for spatial autocorrelation in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d367e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_SPATIAL:\n",
    "    # Initialize spatial dependency handler\n",
    "    sdh = SpatialDependencyHandler(weight_type='queen', standardize=True)\n",
    "    \n",
    "    # Fit the handler to our spatial data\n",
    "    sdh.fit(spatial_df)\n",
    "    \n",
    "    # Create spatially lagged variables\n",
    "    spatial_df_with_lags = sdh.transform(spatial_df)\n",
    "    \n",
    "    # Print new columns\n",
    "    lag_columns = [col for col in spatial_df_with_lags.columns if 'spatial_lag' in col]\n",
    "    print(f\"Created {len(lag_columns)} spatial lag variables:\")\n",
    "    for col in lag_columns:\n",
    "        print(f\"  - {col}\")\n",
    "    \n",
    "    # Examine correlation between variables and their spatial lags\n",
    "    for col in ['walkability', 'income', 'outcome']:\n",
    "        lag_col = f\"{col}_spatial_lag\"\n",
    "        if lag_col in spatial_df_with_lags.columns:\n",
    "            corr = spatial_df_with_lags[[col, lag_col]].corr().iloc[0, 1]\n",
    "            print(f\"Correlation between {col} and its spatial lag: {corr:.3f}\")\n",
    "    \n",
    "    spatial_df_with_lags.head()\n",
    "else:\n",
    "    print(\"Skipping spatial dependency analysis due to missing dependencies.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28530886",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_SPATIAL:\n",
    "    # Compare naive vs. spatially adjusted treatment effects\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    \n",
    "    # Naive estimate (ignoring spatial dependence)\n",
    "    X_naive = spatial_df[['walkability', 'income']]\n",
    "    D = spatial_df['treatment']\n",
    "    Y = spatial_df['outcome']\n",
    "    \n",
    "    # Add treatment to features\n",
    "    X_naive_with_D = pd.concat([X_naive, D], axis=1)\n",
    "    \n",
    "    # Fit naive model\n",
    "    naive_model = LinearRegression()\n",
    "    naive_model.fit(X_naive_with_D, Y)\n",
    "    naive_effect = naive_model.coef_[-1]  # Last coefficient is treatment effect\n",
    "    \n",
    "    # Spatially-adjusted estimate\n",
    "    X_spatial = spatial_df_with_lags[['walkability', 'income', \n",
    "                                    'walkability_spatial_lag', \n",
    "                                    'income_spatial_lag',\n",
    "                                    'outcome_spatial_lag']]\n",
    "    \n",
    "    # Add treatment to features\n",
    "    X_spatial_with_D = pd.concat([X_spatial, D], axis=1)\n",
    "    \n",
    "    # Fit spatial model\n",
    "    spatial_model = LinearRegression()\n",
    "    spatial_model.fit(X_spatial_with_D, Y)\n",
    "    spatial_effect = spatial_model.coef_[-1]  # Last coefficient is treatment effect\n",
    "    \n",
    "    print(f\"Treatment effect (naive): {naive_effect:.3f}\")\n",
    "    print(f\"Treatment effect (spatially adjusted): {spatial_effect:.3f}\")\n",
    "    print(f\"Difference: {spatial_effect - naive_effect:.3f}\")\n",
    "    \n",
    "    # Other approach: use spatial dependency handler directly\n",
    "    # Calculate individual treatment effects (Y - counterfactual Y)\n",
    "    individual_effects = (Y - naive_model.predict(X_naive_with_D)).values\n",
    "    \n",
    "    # Adjust for spatial autocorrelation\n",
    "    adjusted_effects = sdh.adjust_effect_estimates(individual_effects, spatial_df)\n",
    "    \n",
    "    # Compare mean effects\n",
    "    mean_individual_effect = individual_effects.mean()\n",
    "    mean_adjusted_effect = adjusted_effects.mean()\n",
    "    \n",
    "    print(f\"\\nMean individual effect: {mean_individual_effect:.3f}\")\n",
    "    print(f\"Mean adjusted effect: {mean_adjusted_effect:.3f}\")\n",
    "else:\n",
    "    print(\"Skipping spatial treatment effect analysis due to missing dependencies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df4284b",
   "metadata": {},
   "source": [
    "## 4. Visualizing Spatial Treatment Effects\n",
    "\n",
    "Let's visualize the spatial distribution of treatment effects to identify patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad03b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_SPATIAL:\n",
    "    # Add individual treatment effects to the dataframe\n",
    "    spatial_df['individual_effect'] = individual_effects\n",
    "    spatial_df['adjusted_effect'] = adjusted_effects\n",
    "    \n",
    "    # Create plots using the visualization utility\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Plot unadjusted effects\n",
    "    plot_spatial_effects(\n",
    "        spatial_df, \n",
    "        'individual_effect', \n",
    "        title='Unadjusted Treatment Effects',\n",
    "        figsize=(8, 8)\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot adjusted effects\n",
    "    plot_spatial_effects(\n",
    "        spatial_df, \n",
    "        'adjusted_effect', \n",
    "        title='Spatially Adjusted Treatment Effects',\n",
    "        figsize=(8, 8)\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "else:\n",
    "    print(\"Skipping spatial effect visualization due to missing dependencies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a93352",
   "metadata": {},
   "source": [
    "## 5. Creating a Synthetic Longitudinal Dataset\n",
    "\n",
    "Now let's create a synthetic longitudinal (panel) dataset to demonstrate methods for time-varying treatments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8b8306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_panel_data(n_units=50, n_periods=10, treatment_time=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Create synthetic panel data for active transportation research.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_units : int, default=50\n",
    "        Number of units (e.g., neighborhoods)\n",
    "    n_periods : int, default=10\n",
    "        Number of time periods\n",
    "    treatment_time : int, default=5\n",
    "        Time period when treatment starts\n",
    "    random_state : int, default=42\n",
    "        Random seed\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    panel_df : pandas.DataFrame\n",
    "        Panel dataset with units, time periods, and outcomes\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Create unit characteristics (time-invariant)\n",
    "    unit_chars = {\n",
    "        'neighborhood_size': np.random.gamma(5, 2, n_units),\n",
    "        'baseline_walkability': np.random.normal(5, 2, n_units),\n",
    "        'income_level': np.random.lognormal(10, 0.5, n_units),\n",
    "    }\n",
    "    \n",
    "    # Assign treatment to half the units\n",
    "    treatment_assignment = np.zeros(n_units)\n",
    "    treatment_assignment[:n_units//2] = 1\n",
    "    np.random.shuffle(treatment_assignment)\n",
    "    \n",
    "    # Create panel data\n",
    "    panel_data = []\n",
    "    \n",
    "    # Unit-specific trends\n",
    "    unit_trends = np.random.normal(0.1, 0.05, n_units)  # Each unit has slightly different trend\n",
    "    \n",
    "    # Initial active transportation rates\n",
    "    base_outcomes = 20 + 2 * unit_chars['baseline_walkability'] - 0.1 * np.log(unit_chars['income_level'])\n",
    "    \n",
    "    # Generate observations for each unit and time period\n",
    "    for unit in range(n_units):\n",
    "        for period in range(n_periods):\n",
    "            # Treatment indicator (1 if treated unit and after treatment time)\n",
    "            treatment = 1 if (treatment_assignment[unit] == 1 and period >= treatment_time) else 0\n",
    "            \n",
    "            # Outcome equation components:\n",
    "            # 1. Base outcome for this unit\n",
    "            outcome = base_outcomes[unit]\n",
    "            \n",
    "            # 2. Time trend specific to this unit\n",
    "            outcome += period * unit_trends[unit]\n",
    "            \n",
    "            # 3. Seasonal effects (sine wave with period 4)\n",
    "            outcome += 1.5 * np.sin(period * np.pi / 2)\n",
    "            \n",
    "            # 4. Treatment effect (growing over time after treatment)\n",
    "            if treatment == 1:\n",
    "                # Treatment effect grows over time after implementation\n",
    "                time_since_treatment = period - treatment_time + 1\n",
    "                treatment_effect = 3 * (1 - np.exp(-0.5 * time_since_treatment))\n",
    "                outcome += treatment_effect\n",
    "            \n",
    "            # 5. Random noise\n",
    "            outcome += np.random.normal(0, 1)\n",
    "            \n",
    "            # Add record to panel data\n",
    "            panel_data.append({\n",
    "                'unit_id': unit,\n",
    "                'period': period,\n",
    "                'treatment': treatment,\n",
    "                'outcome': outcome,\n",
    "                'neighborhood_size': unit_chars['neighborhood_size'][unit],\n",
    "                'baseline_walkability': unit_chars['baseline_walkability'][unit],\n",
    "                'income_level': unit_chars['income_level'][unit],\n",
    "                # Add time-varying covariates\n",
    "                'precipitation': np.random.gamma(2, 2),  # mm of rain\n",
    "                'gas_price': 3 + 0.05 * period + np.random.normal(0, 0.1)  # Increasing gas prices\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(panel_data)\n",
    "\n",
    "# Create synthetic panel data\n",
    "panel_df = create_synthetic_panel_data(n_units=80, n_periods=12)\n",
    "print(f\"Created synthetic panel data with {len(panel_df)} observations\")\n",
    "panel_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9857268",
   "metadata": {},
   "source": [
    "## 6. Exploring the Panel Data\n",
    "\n",
    "Let's explore our synthetic panel data to understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093c31d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary statistics\n",
    "panel_summary = panel_df.groupby(['period', 'treatment'])['outcome'].agg(['mean', 'std', 'count'])\n",
    "print(\"Summary statistics by period and treatment:\")\n",
    "print(panel_summary)\n",
    "\n",
    "# Plot time trends for treated and control groups\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Calculate mean outcomes by period and treatment status\n",
    "trends = panel_df.groupby(['period', 'treatment'])['outcome'].mean().unstack()\n",
    "\n",
    "# Plot trends\n",
    "plt.plot(trends.index, trends[0], 'b-', label='Control Group')\n",
    "plt.plot(trends.index, trends[1], 'r-', label='Treated Group')\n",
    "\n",
    "# Add reference line at treatment time\n",
    "plt.axvline(x=5, color='g', linestyle='--', label='Treatment Start')\n",
    "\n",
    "plt.xlabel('Time Period')\n",
    "plt.ylabel('Mean Outcome')\n",
    "plt.title('Time Trends in Outcome by Treatment Status')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8508aa",
   "metadata": {},
   "source": [
    "## 7. Difference-in-Differences Analysis\n",
    "\n",
    "Now let's use the `LongitudinalDataHandler` to perform difference-in-differences analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cf8689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize longitudinal data handler for diff-in-diff\n",
    "ldh_did = LongitudinalDataHandler(method='did', aggregation='mean')\n",
    "\n",
    "# Fit the handler to our panel data\n",
    "ldh_did.fit(\n",
    "    X=panel_df,\n",
    "    D=panel_df['treatment'],\n",
    "    Y=panel_df['outcome'],\n",
    "    time_var='period',\n",
    "    id_var='unit_id'\n",
    ")\n",
    "\n",
    "# Get the treatment effect estimate\n",
    "did_effect = ldh_did.estimate_effect()\n",
    "print(f\"Difference-in-Differences treatment effect estimate: {did_effect:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ade5824",
   "metadata": {},
   "source": [
    "## 8. Event Study Analysis\n",
    "\n",
    "Let's create an event study plot to see how the treatment effect evolves over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70f7ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create event study plot\n",
    "event_study_plot = ldh_did.event_study_plot(time_range=(-5, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e149e97a",
   "metadata": {},
   "source": [
    "## 9. Fixed Effects Analysis\n",
    "\n",
    "Now let's use a two-way fixed effects model to account for unit-specific and time-specific factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2af5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize longitudinal data handler for fixed effects\n",
    "ldh_fe = LongitudinalDataHandler(method='fe')\n",
    "\n",
    "# Fit the handler to our panel data\n",
    "ldh_fe.fit(\n",
    "    X=panel_df,\n",
    "    D=panel_df['treatment'],\n",
    "    Y=panel_df['outcome'],\n",
    "    time_var='period',\n",
    "    id_var='unit_id'\n",
    ")\n",
    "\n",
    "# Get the treatment effect estimate\n",
    "fe_effect = ldh_fe.estimate_effect()\n",
    "print(f\"Fixed Effects treatment effect estimate: {fe_effect:.3f}\")\n",
    "\n",
    "# Compare with DID estimate\n",
    "print(f\"Difference from DID estimate: {fe_effect - did_effect:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0dcdae",
   "metadata": {},
   "source": [
    "## 10. Combining Spatial and Longitudinal Analysis\n",
    "\n",
    "For a real application, we might want to combine spatial and longitudinal methods. Let's demonstrate this approach with a synthetic spatio-temporal dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8f43b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_SPATIAL:\n",
    "    try:\n",
    "        # Create a spatial panel dataset\n",
    "        spatial_panel_df = create_spatial_panel_data(\n",
    "            geo_df=spatial_df,\n",
    "            n_periods=8,\n",
    "            treatment_time=4,\n",
    "            spatial_correlation=0.3,\n",
    "            temporal_correlation=0.7,\n",
    "            seed=123\n",
    "        )\n",
    "        \n",
    "        print(f\"Created spatial panel dataset with {len(spatial_panel_df)} observations\")\n",
    "        print(spatial_panel_df.head())\n",
    "        \n",
    "        # Plot outcomes over time by treatment status\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Calculate mean outcomes by period and treatment status\n",
    "        spatio_trends = spatial_panel_df.groupby(['time', 'treatment'])['outcome'].mean().unstack()\n",
    "        \n",
    "        # Plot trends\n",
    "        plt.plot(spatio_trends.index, spatio_trends[0], 'b-', label='Control Group')\n",
    "        plt.plot(spatio_trends.index, spatio_trends[1], 'r-', label='Treated Group')\n",
    "        \n",
    "        # Add reference line at treatment time\n",
    "        plt.axvline(x=4, color='g', linestyle='--', label='Treatment Start')\n",
    "        \n",
    "        plt.xlabel('Time Period')\n",
    "        plt.ylabel('Mean Outcome')\n",
    "        plt.title('Spatio-temporal Outcome by Treatment Status')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        # Now we can apply both spatial and temporal methods\n",
    "        # Step 1: Create spatial features for each time period\n",
    "        spatial_time_dfs = []\n",
    "        \n",
    "        # Process each time period separately for spatial dependencies\n",
    "        for time in range(spatial_panel_df['time'].max() + 1):\n",
    "            # Extract data for this time period\n",
    "            time_data = spatial_panel_df[spatial_panel_df['time'] == time]\n",
    "            \n",
    "            # Create a temporary GeoDataFrame for this time period\n",
    "            time_gdf = spatial_df.loc[time_data['unit_id']].copy()\n",
    "            time_gdf['outcome'] = time_data['outcome'].values\n",
    "            time_gdf['treatment'] = time_data['treatment'].values\n",
    "            \n",
    "            # Handle spatial dependencies\n",
    "            sdh = SpatialDependencyHandler(weight_type='queen')\n",
    "            sdh.fit(time_gdf)\n",
    "            time_gdf_with_lags = sdh.transform(time_gdf)\n",
    "            \n",
    "            # Add time identifier\n",
    "            time_gdf_with_lags['time'] = time\n",
    "            \n",
    "            # Store processed data\n",
    "            spatial_time_dfs.append(time_gdf_with_lags)\n",
    "        \n",
    "        # Combine all time periods\n",
    "        if len(spatial_time_dfs) > 0:\n",
    "            combined_spatio_temporal = pd.concat(spatial_time_dfs)\n",
    "            print(f\"Created spatio-temporal dataset with {len(combined_spatio_temporal)} observations\")\n",
    "            \n",
    "            # Step 2: Apply longitudinal method to spatial data\n",
    "            spatio_temporal_handler = LongitudinalDataHandler(method='did')\n",
    "            \n",
    "            # Fit the handler\n",
    "            spatio_temporal_handler.fit(\n",
    "                X=combined_spatio_temporal,\n",
    "                D=combined_spatio_temporal['treatment'],\n",
    "                Y=combined_spatio_temporal['outcome'],\n",
    "                time_var='time',\n",
    "                id_var=combined_spatio_temporal.index\n",
    "            )\n",
    "            \n",
    "            # Get the treatment effect estimate\n",
    "            spatio_temporal_effect = spatio_temporal_handler.estimate_effect()\n",
    "            print(f\"\\nSpatiotemporal treatment effect estimate: {spatio_temporal_effect:.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in spatio-temporal analysis: {e}\")\n",
    "else:\n",
    "    print(\"Skipping spatio-temporal analysis due to missing dependencies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f74d4f",
   "metadata": {},
   "source": [
    "## 11. Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to handle spatial dependencies and longitudinal data in causal inference for active transportation research. Key takeaways:\n",
    "\n",
    "1. **Spatial dependencies** can significantly impact effect estimates, and ignoring them may lead to biased results\n",
    "2. **Longitudinal methods** like difference-in-differences and fixed effects help account for time-invariant confounders\n",
    "3. **Event study analysis** provides insights into the temporal dynamics of treatment effects\n",
    "4. **Combined spatio-temporal analysis** offers the most comprehensive approach for transportation interventions\n",
    "\n",
    "These methods are particularly important for active transportation research because:\n",
    "- Infrastructure improvements have spatial spillover effects to nearby areas\n",
    "- Benefits of active transportation infrastructure often grow over time as behavior adapts\n",
    "- Complex confounding factors like neighborhood characteristics require advanced methods"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
