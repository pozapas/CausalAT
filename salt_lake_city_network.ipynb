{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "724f9ef3",
   "metadata": {},
   "source": [
    "# Creating a Stylized Network of Census Tracts\n",
    "\n",
    "This notebook creates a stylized network with approximately 200 census tract nodes using OpenStreetMap statistics. While we use Salt Lake City, Utah as an example, this approach can be easily adapted to any city or region by changing the location parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ce6a05",
   "metadata": {},
   "source": [
    "## How to Use This Notebook for Different Cities\n",
    "\n",
    "This notebook demonstrates how to create a stylized network of census tracts for any city, using Salt Lake City, Utah as an example. To adapt this notebook for a different city:\n",
    "\n",
    "1. **Change the Census parameters**:\n",
    "   - Modify the `state_fips` and `county_fips` variables for your target location\n",
    "   - You can find FIPS codes for US states and counties [here](https://www.census.gov/library/reference/code-lists/ansi.html)\n",
    "\n",
    "2. **Change the OpenStreetMap location**:\n",
    "   - Modify the `place_name` variable with your target city name\n",
    "   - Format: 'City Name, State, Country' (e.g., 'Boston, Massachusetts, USA')\n",
    "\n",
    "All file names and visualizations will automatically use your chosen city name. The methodology remains the same regardless of which US city you analyze."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7712f7",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies\n",
    "\n",
    "First, let's install and import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c1e2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install geopandas osmnx networkx matplotlib contextily cenpy requests lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9e58c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "import warnings\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "import cenpy\n",
    "import random\n",
    "import lxml\n",
    "from shapely.geometry import MultiPolygon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb810767",
   "metadata": {},
   "source": [
    "## 2. Download Census Tract Data\n",
    "\n",
    "We'll use the Census API through cenpy to download census tract data. For this example, we're using Salt Lake City, Utah, but you can modify the state and county codes to analyze any other US city or region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edba2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up cenpy connection\n",
    "conn = cenpy.remote.APIConnection('DECENNIALSF12010')\n",
    "\n",
    "# Example: Salt Lake County FIPS code is 49035 (state 49 = Utah, county 035 = Salt Lake)\n",
    "# Modify these values to analyze a different city/county\n",
    "state_fips = '49'  # Utah\n",
    "county_fips = '035'  # Salt Lake County\n",
    "county_fips_full = state_fips + county_fips\n",
    "\n",
    "# Get census tract data for the selected county\n",
    "variables = ['P001001']  # Total population\n",
    "census_tracts = conn.query(variables, geo_unit='tract:*', geo_filter={'state': state_fips, 'county': county_fips})\n",
    "\n",
    "# Download census tract geometries - using the correct URL format for Census TIGER/Line files\n",
    "try:\n",
    "    # Use the 2024 TIGER/Line data that is available\n",
    "    url = f\"https://www2.census.gov/geo/tiger/TIGER2024/TRACT/tl_2024_{state_fips}_tract.zip\"\n",
    "    print(f\"Attempting to download from: {url}\")\n",
    "    census_tracts_geo = gpd.read_file(url)\n",
    "    print(\"Successfully downloaded 2024 data\")\n",
    "    \n",
    "    # Filter to only the county we want\n",
    "    census_tracts_geo = census_tracts_geo[census_tracts_geo['COUNTYFP'] == county_fips]\n",
    "    print(f\"Filtered to {len(census_tracts_geo)} tracts in county {county_fips}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error with 2024 data: {e}\")\n",
    "    try:\n",
    "        # Try 2022 data as fallback\n",
    "        url = f\"https://www2.census.gov/geo/tiger/TIGER2022/TRACT/tl_2022_{state_fips}_tract.zip\"\n",
    "        print(f\"Attempting to download from: {url}\")\n",
    "        census_tracts_geo = gpd.read_file(url)\n",
    "        # Filter to only the county we want\n",
    "        census_tracts_geo = census_tracts_geo[census_tracts_geo['COUNTYFP'] == county_fips]\n",
    "        print(f\"Successfully downloaded 2022 data and filtered to {len(census_tracts_geo)} tracts in county {county_fips}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error with 2022 data: {e}\")\n",
    "        try:\n",
    "            # Try 2021 data as another fallback\n",
    "            url = f\"https://www2.census.gov/geo/tiger/TIGER2021/TRACT/tl_2021_{state_fips}_tract.zip\"\n",
    "            print(f\"Attempting to download from: {url}\")\n",
    "            census_tracts_geo = gpd.read_file(url)\n",
    "            # Filter to only the county we want\n",
    "            census_tracts_geo = census_tracts_geo[census_tracts_geo['COUNTYFP'] == county_fips]\n",
    "            print(f\"Successfully downloaded 2021 data and filtered to {len(census_tracts_geo)} tracts in county {county_fips}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error with 2021 data: {e}\")\n",
    "            # Try 2020 data as a final fallback\n",
    "            url = f\"https://www2.census.gov/geo/tiger/TIGER2020/TRACT/tl_2020_{state_fips}_tract.zip\"\n",
    "            print(f\"Attempting to download from: {url}\")\n",
    "            census_tracts_geo = gpd.read_file(url)\n",
    "            # Filter to only the county we want\n",
    "            census_tracts_geo = census_tracts_geo[census_tracts_geo['COUNTYFP'] == county_fips]\n",
    "            print(f\"Successfully downloaded 2020 data and filtered to {len(census_tracts_geo)} tracts in county {county_fips}\")\n",
    "\n",
    "# Join the geometries with the census data\n",
    "census_tracts_geo['tract'] = census_tracts_geo['TRACTCE']\n",
    "census_tracts = pd.merge(census_tracts, census_tracts_geo, on='tract')\n",
    "census_tracts = gpd.GeoDataFrame(census_tracts, geometry='geometry')\n",
    "\n",
    "# Display the first few census tracts\n",
    "census_tracts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460ae658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample down to approximately 200 census tracts if there are more\n",
    "if len(census_tracts) > 200:\n",
    "    census_tracts = census_tracts.sample(n=200, random_state=42)\n",
    "else:\n",
    "    print(f\"There are only {len(census_tracts)} census tracts in the selected county\")\n",
    "    \n",
    "census_tracts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74283b6a",
   "metadata": {},
   "source": [
    "## 3. Download OpenStreetMap Data\n",
    "\n",
    "Now we'll download road network data from OpenStreetMap. For this example, we're using Salt Lake City, but you can easily change the place parameter to analyze any other city or region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b023c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the place name - change this to analyze a different city\n",
    "place_name = 'Salt Lake City, Utah, USA'  # Example location\n",
    "\n",
    "warnings.filterwarnings('ignore')  # Suppress warnings\n",
    "\n",
    "try:\n",
    "    print(f\"Downloading street network data for {place_name}...\")\n",
    "    try:\n",
    "        # Try using the address method first\n",
    "        city_graph = ox.graph_from_address(place_name, network_type='drive', dist=5000)  # 5km radius\n",
    "        print(\"Successfully downloaded using graph_from_address\")\n",
    "    except Exception as e1:\n",
    "        print(f\"Address method failed: {e1}\")\n",
    "        try:\n",
    "            # Try with nominatim approach\n",
    "            import geopandas as gpd\n",
    "            from shapely.geometry import box\n",
    "            \n",
    "            # Get a bounding box for the area\n",
    "            gdf = ox.geocode_to_gdf(place_name)\n",
    "            if len(gdf) == 0:\n",
    "                raise ValueError(f\"Could not geocode {place_name}\")\n",
    "                \n",
    "            # Create a bounding box\n",
    "            bbox = box(*gdf.total_bounds)\n",
    "            \n",
    "            # Get the network within this boundary\n",
    "            city_graph = ox.graph_from_polygon(bbox, network_type='drive')\n",
    "            print(\"Successfully downloaded using graph_from_polygon with bounding box\")\n",
    "        except Exception as e2:\n",
    "            print(f\"Polygon method failed: {e2}\")\n",
    "            # Final fallback - use coordinates for Salt Lake City and get a network around it\n",
    "            center_lat, center_lng = 40.7608, -111.8910  # Salt Lake City coordinates\n",
    "            city_graph = ox.graph_from_point((center_lat, center_lng), dist=5000, network_type='drive')\n",
    "            print(\"Successfully downloaded using fallback graph_from_point\")\n",
    "    \n",
    "    # Convert the OSM graph to GeoPandas for visualization\n",
    "    nodes, edges = ox.graph_to_gdfs(city_graph)\n",
    "    \n",
    "    # Display basic stats\n",
    "    print(f\"Number of nodes: {len(nodes)}\")\n",
    "    print(f\"Number of edges: {len(edges)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error downloading OpenStreetMap data: {e}\")\n",
    "    print(\"Using a simple fallback approach...\")\n",
    "    \n",
    "    # Fallback to hardcoded coordinates for Salt Lake City\n",
    "    center_lat, center_lng = 40.7608, -111.8910  # Salt Lake City coordinates\n",
    "    city_graph = ox.graph_from_point((center_lat, center_lng), dist=5000, network_type='drive')\n",
    "    nodes, edges = ox.graph_to_gdfs(city_graph)\n",
    "    print(f\"Fallback successful - Number of nodes: {len(nodes)}, Number of edges: {len(edges)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2828457b",
   "metadata": {},
   "source": [
    "## 4. Create a Stylized Network of Census Tracts\n",
    "\n",
    "Now we'll create a network where nodes represent census tracts, and edges represent connections between tracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37fd530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a NetworkX graph for census tracts\n",
    "tract_graph = nx.Graph()\n",
    "\n",
    "# Add census tracts as nodes\n",
    "# Use the centroid of each tract as the node position\n",
    "for idx, tract in census_tracts.iterrows():\n",
    "    # Handle MultiPolygon vs Polygon geometry types\n",
    "    if isinstance(tract.geometry, MultiPolygon):\n",
    "        # For MultiPolygon, use the centroid of the largest polygon\n",
    "        largest_poly = max(tract.geometry.geoms, key=lambda x: x.area)\n",
    "        centroid = largest_poly.centroid\n",
    "    else:\n",
    "        centroid = tract.geometry.centroid\n",
    "    \n",
    "    # Add node with attributes\n",
    "    tract_graph.add_node(idx, \n",
    "                        pos=(centroid.x, centroid.y),\n",
    "                        tract_id=tract.get('GEOID', str(idx)),\n",
    "                        geometry=tract.geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61978af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create edges between adjacent census tracts\n",
    "# Two tracts are connected if they share a boundary\n",
    "\n",
    "# Create a spatial index for more efficient querying\n",
    "census_tracts.sindex\n",
    "\n",
    "# For each tract, find neighbors and create edges\n",
    "for idx1, tract1 in census_tracts.iterrows():\n",
    "    # Find potential neighbors (tracts that might intersect)\n",
    "    possible_matches_idx = list(census_tracts.sindex.intersection(tract1.geometry.bounds))\n",
    "    possible_matches = census_tracts.iloc[possible_matches_idx]\n",
    "    \n",
    "    # Filter to tracts that actually touch this tract\n",
    "    neighbors = possible_matches[possible_matches.geometry.touches(tract1.geometry)]\n",
    "    \n",
    "    # Add edges to the graph for each neighbor\n",
    "    for idx2, tract2 in neighbors.iterrows():\n",
    "        if idx1 != idx2:  # Don't add self-loops\n",
    "            # Calculate the length of shared boundary as edge weight\n",
    "            shared_boundary = tract1.geometry.intersection(tract2.geometry)\n",
    "            boundary_length = shared_boundary.length\n",
    "            \n",
    "            # Add edge with the boundary length as a weight\n",
    "            tract_graph.add_edge(idx1, idx2, weight=boundary_length)\n",
    "\n",
    "# Print some network statistics\n",
    "print(f\"Number of nodes: {len(tract_graph.nodes())}\")\n",
    "print(f\"Number of edges: {len(tract_graph.edges())}\")\n",
    "print(f\"Is connected: {nx.is_connected(tract_graph)}\")\n",
    "\n",
    "# Handle disconnected components by connecting them to their nearest neighbors\n",
    "if not nx.is_connected(tract_graph):\n",
    "    print(\"\\nThe graph has disconnected components. Adding connections to make it connected...\")\n",
    "    \n",
    "    # Get the connected components\n",
    "    components = list(nx.connected_components(tract_graph))\n",
    "    print(f\"Number of disconnected components: {len(components)}\")\n",
    "    \n",
    "    # Function to find the closest pair of nodes between two components\n",
    "    def find_closest_nodes(comp1, comp2):\n",
    "        min_dist = float('inf')\n",
    "        closest_pair = None\n",
    "        \n",
    "        for node1 in comp1:\n",
    "            pos1 = tract_graph.nodes[node1]['pos']\n",
    "            for node2 in comp2:\n",
    "                pos2 = tract_graph.nodes[node2]['pos']\n",
    "                \n",
    "                # Calculate Euclidean distance\n",
    "                dist = ((pos1[0] - pos2[0])**2 + (pos1[1] - pos2[1])**2)**0.5\n",
    "                \n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    closest_pair = (node1, node2)\n",
    "        \n",
    "        return closest_pair, min_dist\n",
    "    \n",
    "    # Connect each component to the main component (the largest one)\n",
    "    main_component = max(components, key=len)\n",
    "    other_components = [c for c in components if c != main_component]\n",
    "    \n",
    "    for i, component in enumerate(other_components):\n",
    "        # Find closest nodes between this component and the main component\n",
    "        closest_pair, distance = find_closest_nodes(main_component, component)\n",
    "        \n",
    "        if closest_pair:\n",
    "            node1, node2 = closest_pair\n",
    "            # Add an edge between the closest nodes with a weight inversely proportional to distance\n",
    "            tract_graph.add_edge(node1, node2, weight=1/distance, is_artificial=True)\n",
    "            print(f\"Connected component {i+1} to main component with edge between nodes {node1} and {node2}\")\n",
    "    \n",
    "    print(f\"After connecting: Is connected: {nx.is_connected(tract_graph)}\")\n",
    "    print(f\"Total edges after connecting: {len(tract_graph.edges())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b24351d",
   "metadata": {},
   "source": [
    "## 5. Extract OpenStreetMap Statistics for Each Census Tract\n",
    "\n",
    "We'll now collect statistics from OSM data for each census tract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6ae479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed function to calculate OSM statistics for a tract\n",
    "def calculate_osm_stats(tract_geometry, edges_gdf):\n",
    "    # Check if edges_gdf is a valid GeoDataFrame\n",
    "    if not isinstance(edges_gdf, gpd.GeoDataFrame):\n",
    "        print(f\"Warning: edges_gdf is not a GeoDataFrame but {type(edges_gdf)}\")\n",
    "        # Return empty stats\n",
    "        return {\n",
    "            'road_length': 0,\n",
    "            'road_segments': 0,\n",
    "            'primary_roads': 0,\n",
    "            'residential_roads': 0,\n",
    "            'average_speed': np.nan\n",
    "        }\n",
    "        \n",
    "    try:\n",
    "        # Clip the road network to this tract\n",
    "        roads_in_tract = gpd.clip(edges_gdf, tract_geometry)\n",
    "        \n",
    "        # Helper function to convert speed values (handles \"20 mph\" format)\n",
    "        def parse_speed(speed_value):\n",
    "            # Handle missing and empty values\n",
    "            if speed_value is None or (isinstance(speed_value, float) and np.isnan(speed_value)) or (isinstance(speed_value, str) and speed_value.strip() == ''):\n",
    "                return np.nan\n",
    "            # Handle list/sequence values\n",
    "            if isinstance(speed_value, (list, tuple, np.ndarray, pd.Series)):\n",
    "                for val in speed_value:\n",
    "                    parsed = parse_speed(val)\n",
    "                    if not (isinstance(parsed, float) and np.isnan(parsed)):\n",
    "                        return parsed\n",
    "                return np.nan\n",
    "            # Convert string value\n",
    "            if isinstance(speed_value, str):\n",
    "                import re\n",
    "                match = re.search(r\"(\\d+)\", speed_value)\n",
    "                if match:\n",
    "                    return float(match.group(1))\n",
    "            # Numeric values\n",
    "            if isinstance(speed_value, (int, float)):\n",
    "                return float(speed_value)\n",
    "            return np.nan\n",
    "\n",
    "        # Apply speed parsing to all values and calculate average\n",
    "        speeds = roads_in_tract['maxspeed'].apply(parse_speed) if 'maxspeed' in roads_in_tract.columns else pd.Series([])\n",
    "        avg_speed = speeds.mean(skipna=True)\n",
    "        \n",
    "        # FIXED: Improved helper function to check if a highway value matches any of the given types\n",
    "        def is_highway_type(highway_value, types):\n",
    "            # Handle missing values\n",
    "            if highway_value is None or (isinstance(highway_value, float) and np.isnan(highway_value)):\n",
    "                return False\n",
    "            # String case\n",
    "            if isinstance(highway_value, str):\n",
    "                return highway_value in types\n",
    "            # Iterable case\n",
    "            if isinstance(highway_value, (list, tuple, np.ndarray, pd.Series)):\n",
    "                try:\n",
    "                    iterable = list(highway_value)\n",
    "                except Exception:\n",
    "                    return False\n",
    "                for h in iterable:\n",
    "                    if isinstance(h, str) and h in types:\n",
    "                        return True\n",
    "                return False\n",
    "            return False\n",
    "        \n",
    "        # Calculate road type counts using improved method\n",
    "        primary_road_types = ['primary', 'trunk', 'motorway']\n",
    "        residential_road_types = ['residential']\n",
    "        \n",
    "        if 'highway' in roads_in_tract.columns and not roads_in_tract.empty:\n",
    "            # Use a safer approach to count road types\n",
    "            primary_roads = 0\n",
    "            residential_roads = 0\n",
    "            \n",
    "            for _, row in roads_in_tract.iterrows():\n",
    "                highway_val = row['highway']\n",
    "                if is_highway_type(highway_val, primary_road_types):\n",
    "                    primary_roads += 1\n",
    "                if is_highway_type(highway_val, residential_road_types):\n",
    "                    residential_roads += 1\n",
    "        else:\n",
    "            primary_roads = 0\n",
    "            residential_roads = 0\n",
    "        \n",
    "        # Calculate statistics\n",
    "        stats = {\n",
    "            'road_length': roads_in_tract.length.sum() if not roads_in_tract.empty else 0,\n",
    "            'road_segments': len(roads_in_tract),\n",
    "            'primary_roads': primary_roads,\n",
    "            'residential_roads': residential_roads,\n",
    "            'average_speed': avg_speed\n",
    "        }\n",
    "        return stats\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in calculate_osm_stats: {e}\")\n",
    "        # Return empty stats on error\n",
    "        return {\n",
    "            'road_length': 0,\n",
    "            'road_segments': 0,\n",
    "            'primary_roads': 0,\n",
    "            'residential_roads': 0,\n",
    "            'average_speed': np.nan\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2a493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate OSM statistics for each tract and add to node attributes\n",
    "try:\n",
    "    # Re-get the edges GeoDataFrame if needed\n",
    "    if not isinstance(edges, gpd.GeoDataFrame):\n",
    "        print(\"Re-creating the edges GeoDataFrame from the city_graph...\")\n",
    "        _, edges = ox.graph_to_gdfs(city_graph)\n",
    "        print(f\"Created edges GeoDataFrame with {len(edges)} rows\")\n",
    "    \n",
    "    # Calculate OSM statistics for each tract and add to node attributes\n",
    "    print(\"Calculating OSM statistics for each census tract...\")\n",
    "    for node_id in tract_graph.nodes():\n",
    "        tract_geometry = tract_graph.nodes[node_id]['geometry']\n",
    "        try:\n",
    "            stats = calculate_osm_stats(tract_geometry, edges)\n",
    "            # Add stats as node attributes\n",
    "            nx.set_node_attributes(tract_graph, {node_id: stats})\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating stats for node {node_id}: {e}\")\n",
    "            # Add empty stats to avoid issues with later code\n",
    "            empty_stats = {\n",
    "                'road_length': 0,\n",
    "                'road_segments': 0,\n",
    "                'primary_roads': 0,\n",
    "                'residential_roads': 0,\n",
    "                'average_speed': np.nan\n",
    "            }\n",
    "            nx.set_node_attributes(tract_graph, {node_id: empty_stats})\n",
    "    \n",
    "    print(\"OSM statistics calculation completed\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error processing OSM statistics: {e}\")\n",
    "    print(\"Setting default empty statistics for all nodes\")\n",
    "    \n",
    "    # Set empty stats for all nodes\n",
    "    empty_stats = {\n",
    "        'road_length': 0,\n",
    "        'road_segments': 0,\n",
    "        'primary_roads': 0,\n",
    "        'residential_roads': 0,\n",
    "        'average_speed': np.nan\n",
    "    }\n",
    "    \n",
    "    # Add empty stats to all nodes\n",
    "    for node_id in tract_graph.nodes():\n",
    "        nx.set_node_attributes(tract_graph, {node_id: empty_stats})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b718b98",
   "metadata": {},
   "source": [
    "## 6. Visualize the Stylized Network\n",
    "\n",
    "Now let's create a visualization of our network with 200 census tract nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb19b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract node positions\n",
    "node_positions = nx.get_node_attributes(tract_graph, 'pos')\n",
    "\n",
    "# Set up the figure\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "# Draw census tract boundaries\n",
    "census_tracts.plot(ax=plt.gca(), facecolor='none', edgecolor='gray', alpha=0.3)\n",
    "\n",
    "# Draw the network\n",
    "nx.draw_networkx(\n",
    "    tract_graph, \n",
    "    pos=node_positions,\n",
    "    node_size=50,\n",
    "    node_color='blue',\n",
    "    edge_color='red',\n",
    "    alpha=0.7,\n",
    "    with_labels=False\n",
    ")\n",
    "\n",
    "# Add basemap for context\n",
    "ctx.add_basemap(plt.gca(), crs=census_tracts.crs.to_string(), source=ctx.providers.CartoDB.Positron)\n",
    "\n",
    "plt.title(f'Stylized Network of Census Tracts in {place_name}')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Create a filename based on the place name (removing spaces and commas)\n",
    "clean_name = place_name.replace(', ', '_').replace(' ', '_').lower()\n",
    "plt.savefig(f'{clean_name}_network.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc61c146",
   "metadata": {},
   "source": [
    "## 7. Advanced Visualization with Node Attributes from OSM Data\n",
    "\n",
    "Let's create a more informative visualization using the OSM statistics we collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa80336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract road length data for node sizing\n",
    "road_lengths = []\n",
    "for node in tract_graph.nodes():\n",
    "    road_length = tract_graph.nodes[node].get('road_length', 0)\n",
    "    road_lengths.append(road_length)\n",
    "\n",
    "# Normalize for visualization - handle case where all road lengths are 0\n",
    "max_length = max(road_lengths) if road_lengths and max(road_lengths) > 0 else 1\n",
    "# Avoid division by zero by using a default size when max_length is 0\n",
    "node_sizes = [100 * (length / max_length) + 20 if max_length > 0 else 50 for length in road_lengths]\n",
    "\n",
    "# Set up the figure\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "# Draw census tract boundaries\n",
    "census_tracts.plot(ax=plt.gca(), facecolor='none', edgecolor='gray', alpha=0.3)\n",
    "\n",
    "# Draw the network with node sizes based on road length\n",
    "nx.draw_networkx(\n",
    "    tract_graph, \n",
    "    pos=node_positions,\n",
    "    node_size=node_sizes,\n",
    "    node_color='blue',\n",
    "    edge_color='red',\n",
    "    alpha=0.7,\n",
    "    with_labels=False\n",
    ")\n",
    "\n",
    "# Add basemap for context\n",
    "ctx.add_basemap(plt.gca(), crs=census_tracts.crs.to_string(), source=ctx.providers.CartoDB.Positron)\n",
    "\n",
    "plt.title(f'{place_name} Network: Node Size Represents Total Road Length')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{clean_name}_network_with_attributes.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d391c5",
   "metadata": {},
   "source": [
    "## 8. Export the Network for Further Analysis\n",
    "\n",
    "Let's export our network for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfde6468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the network to GraphML format\n",
    "tract_graph_export = tract_graph.copy()\n",
    "\n",
    "   \n",
    "# Process node attributes for GraphML compatibility\n",
    "for node in tract_graph_export.nodes():\n",
    "    node_data = tract_graph_export.nodes[node]\n",
    "    \n",
    "    # Remove geometry attribute (not serializable)\n",
    "    if 'geometry' in node_data:\n",
    "        del node_data['geometry']\n",
    "    \n",
    "    # Convert position tuple to string\n",
    "    if 'pos' in node_data:\n",
    "        pos = node_data['pos']\n",
    "        if isinstance(pos, tuple):\n",
    "            node_data['pos'] = f\"{pos[0]},{pos[1]}\"\n",
    "    \n",
    "    # Convert any numpy values to Python native types\n",
    "    for attr in list(node_data.keys()):\n",
    "        if isinstance(node_data[attr], (np.int64, np.int32, np.float64, np.float32)):\n",
    "            node_data[attr] = node_data[attr].item()\n",
    "        elif pd.isna(node_data[attr]):\n",
    "            # Replace NaN values with string representation\n",
    "            node_data[attr] = \"NA\"\n",
    "        elif isinstance(node_data[attr], (list, tuple)):\n",
    "            # Convert lists/tuples to string representation\n",
    "            node_data[attr] = str(node_data[attr])\n",
    "    \n",
    "# Process edge attributes for GraphML compatibility\n",
    "for u, v, data in tract_graph_export.edges(data=True):\n",
    "    # Convert any numpy values to Python native types\n",
    "    for attr in list(data.keys()):\n",
    "        if isinstance(data[attr], (np.int64, np.int32, np.float64, np.float32)):\n",
    "            data[attr] = data[attr].item()\n",
    "        elif pd.isna(data[attr]):\n",
    "            # Replace NaN values with string representation\n",
    "            data[attr] = \"NA\"\n",
    "        elif isinstance(data[attr], (list, tuple)):\n",
    "            # Convert lists/tuples to string representation\n",
    "            data[attr] = str(data[attr])\n",
    "            \n",
    "# Try alternative export methods if write_graphml fails\n",
    "try:\n",
    "    nx.write_graphml(tract_graph_export, f'{clean_name}_tract_network.graphml')\n",
    "    print(f\"Successfully exported network to {clean_name}_tract_network.graphml\")\n",
    "except Exception as e:\n",
    "    print(f\"GraphML export failed: {e}\")\n",
    "    print(\"Trying with ignore_dicts parameter...\")\n",
    "    \n",
    "    try:\n",
    "        # Try with ignore_dicts=True which can help with incompatible values\n",
    "        nx.write_graphml(tract_graph_export, f'{clean_name}_tract_network.graphml', infer_numeric_types=True)\n",
    "        print(f\"Successfully exported network to {clean_name}_tract_network.graphml using infer_numeric_types\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Second GraphML export attempt failed: {e2}\")\n",
    "        print(\"Exporting to GEXF format instead...\")\n",
    "        \n",
    "        try:\n",
    "            nx.write_gexf(tract_graph_export, f'{clean_name}_tract_network.gexf')\n",
    "            print(f\"Successfully exported network to {clean_name}_tract_network.gexf\")\n",
    "        except Exception as e3:\n",
    "            print(f\"GEXF export also failed: {e3}\")\n",
    "            print(\"Trying with simplest format, edge list...\")\n",
    "            \n",
    "            try:\n",
    "                nx.write_edgelist(tract_graph_export, f'{clean_name}_tract_network.edges')\n",
    "                print(f\"Successfully exported network as edge list to {clean_name}_tract_network.edges\")\n",
    "            except Exception as e4:\n",
    "                print(f\"Edge list export also failed: {e4}\")\n",
    "                \n",
    "# Save node and edge data to CSV for easy import into other tools\n",
    "nodes_df = pd.DataFrame.from_dict(dict(tract_graph.nodes(data=True)), orient='index')\n",
    "\n",
    "# Convert geometry objects to WKT strings for saving\n",
    "if 'geometry' in nodes_df.columns:\n",
    "    nodes_df['geometry_wkt'] = nodes_df['geometry'].apply(lambda x: x.wkt if x else None)\n",
    "    nodes_df = nodes_df.drop(columns=['geometry'])\n",
    "\n",
    "nodes_df.to_csv(f'{clean_name}_tract_nodes.csv')\n",
    "\n",
    "# Handle edges\n",
    "edges_df = pd.DataFrame([(u, v, d) for u, v, d in tract_graph.edges(data=True)])\n",
    "if not edges_df.empty:  # Check if there are any edges\n",
    "    edges_df.columns = ['source', 'target', 'attributes']\n",
    "    edges_df.to_csv(f'{clean_name}_tract_edges.csv')\n",
    "\n",
    "print(\"Network data exported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a35f461",
   "metadata": {},
   "source": [
    "## Summary of Network Creation and Export\n",
    "\n",
    "This notebook has successfully created a stylized network of census tracts using OpenStreetMap data for Salt Lake City. Here's a summary of what we've accomplished:\n",
    "\n",
    "1. **Data Collection**:\n",
    "   - Downloaded census tract data for Salt Lake County, Utah\n",
    "   - Retrieved OpenStreetMap road network data for the area\n",
    "   - Filtered to approximately 200 census tracts\n",
    "\n",
    "2. **Network Creation**:\n",
    "   - Built a network where nodes represent census tracts\n",
    "   - Created edges between adjacent census tracts\n",
    "   - Ensured the network is fully connected by adding necessary edges between disconnected components\n",
    "\n",
    "3. **Network Analysis**:\n",
    "   - Calculated road statistics for each census tract (length, segments, types, speeds)\n",
    "   - Created visualizations with node sizes representing road lengths\n",
    "   - Added travel time calculations for edges using Euclidean distance, 25mph average speed, and log-normal perturbation\n",
    "\n",
    "4. **Data Export**:\n",
    "   - Exported the network to GraphML format for use in other network analysis tools\n",
    "   - Saved node and edge data as CSV files\n",
    "   - Generated visualizations showing the network structure and travel times\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
